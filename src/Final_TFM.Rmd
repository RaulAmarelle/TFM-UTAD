---
title: "Trabajo Final Master"
author: "Raul Amarelle"
date: "1 de septiembre de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Cargamos librerias necesarias para todo el proyecto

```{r}
library(readxl)
library(cluster)
library(ggplot2)
library(mclust)
library(fpc)
library(dplyr)
library(stats)
library(lubridate)
library(CausalImpact)
library(data.table)
library(bsts)
library(car)
library(zoo)
library(rpart) # decision tree method
library(rpart.plot) # tree plot
library(party) # decision tree method
library(forecast) # forecasting methods
library(tseries)
library(MLmetrics)
library(grid) # visualizations
library(animation) # gif
library(reshape)

```


En primer lugar, leemos los datos de nuestro data set

```{r}

data <- read_excel("../dat/Datos.xls")
df.data <- as.data.frame(data)
View(df.data)
```


ANALISIS VARIABLES  

Este dataset es una recopilacion de datos diarios de temperatura y potencia consumida relativos a un centro comercial.

Breve explicacion de las variables:
1. Fecha: fecha de la medicion, hay una medicion diaria  
2. Estimado: no sirve de nada  
3. Kwh: potencia consumida  
4. LB: Linea base, es decir, la prediccion de potencia consumida  
5 a 10. CCD o CCHD: Cooling-Degree Day o Cooling Heating Degree Day son temperaturas recogidas en 6 columnas. Es la diferencia entre el promedio diario de temperatura y una determinada temperatura base de referencia (suele ser la exterior). El centro comercial tiene dos modos de climatizacion: calentar o enfriar, por eso son siempre 3 ceros vs 3 numeros. 18, 19 y 20 es la temperatura base en ambos casos. Por eso el valor es siempre el mismo sumando o restando 1 de una columna a la siguiente.  
11. Afluencia: Numero de personas visitantes.  


Quiere decir que de las 3+3 columnas de temperatura, 2+2 son redundantes. Con quedarnos una columna de cada modo de climatizacion, es suficiente. Escogemos CCDD20 y CHDD18, porque son las columnas mas ventajosas.


##########################
#  TRATAMIENTO DE DATOS  #
##########################

1. Eliminamos las variables que no aportan informacion

```{r}
# segun lo comentado anteriormente

df.data <- df.data[,-c(2, 5, 6, 9, 10)]
View(df.data)
```


2. Hacemos un preanalisis de variables

```{r}
dim(df.data)
str(df.data)
summary(df.data)
```


3. Creacion de nuevas variables

```{r}
# Vamos a crear nuevas columnas para dia, mes y anio, nos pueden ser de utilidad para segmentar las predicciones segun periodo. 

df.data$DAY <- day(dmy(df.data$FECHA))
df.data$MONTH <- month(dmy(df.data$FECHA))
df.data$YEAR <- year(dmy(df.data$FECHA))

str(df.data)
View(df.data)
```

```{r}
# Cambiamos la clase a variable FECHA, para que pase de chr a Date

df.data$FECHA <- as.Date(df.data$FECHA, format="%d/%m/%Y")

str(df.data)

```


A priori parece interesante crear una columna categorica Entre Semana (ES) y Fin de Semana (FS), para analizar posibles cambios de comportamiento.

```{r}
# En primer lugar creamos la variable WEEKDAY que nos dice que a dia de la semana corresponde cada fecha

df.data$WEEKDAY <- weekdays(df.data$FECHA)

# Creamos la variable categorica 
df.data$FINDE <- ifelse(df.data$WEEKDAY %in% c('sábado', 'domingo'), 'FS', 'ES')

View(df.data)
```


Creamos la variable categorica Climatizacion, con 3 opciones en funcion del gradiente de temperatura:

```{r}
#   - Heating: CCDD20 es 0 y CHDD18 tiene valor
#   - Cooling: CCDD20 tiene valor y CHDD18 es 0
#   - Neutro: tanto CCDD20 como CHDD18 son 0

df.data$CLIMATIZACION <- ifelse(df.data$CCDD20 > 0, 'Cooling',
                                         ifelse(df.data$CHDD18 > 0, 'Heating', 'Neutro'))

View(df.data)
```


Creamos una nueva columna, que la llamaremos ERROR, que sera el % de error del modelo actual.

```{r}
# Compara la potencia consumida real vs la prevision
df.data$ERROR <- (df.data$KWH-df.data$LB)/df.data$KWH * 100

View(df.data)
```


4. Tratamiento de Missing Values

```{r}
# Vamos a calcular los N/A del dataset
nas <- nrow(data[data$CHDD18!=0 & data$CCDD20!=0,])
nas

# Solo hay 4 muestras N/A, aprox el 0.5% de los datos
nas / nrow(df.data) *100

# Considero que puedo eliminar esas filas porque, aparte de ser un numero muy bajo y poco representativo, no se puede saber si ese dia el sistema funciono bajo regimen de calefaccion o refrigeracion, por lo que no podre extraer conclusiones
df.data <- df.data[!is.na(df.data$CCDD20),]

View(df.data)
```


############################
#  VISUALIZACION DE DATOS  #
############################

1. Distribucion con funciones de densidad

```{r}
ggplot() +
  geom_density(data = df.data, aes(x = scale(KWH), colour = 'kWh')) +
  geom_density(data = df.data, aes(x = scale(LB), colour = 'LB')) +
  geom_density(data = df.data, aes(x = scale(CCDD20), colour = 'CCDD20')) +
  geom_density(data = df.data, aes(x = scale(CHDD18), colour = 'CHDD18')) + 
  geom_density(data = df.data, aes(x = scale(AFLUENCIA), colour = 'AFLUENCIA')) + 
  scale_colour_manual('', breaks = c('KWH', 'LB', 'CCDD20', 'CHDD18', 'AFLUENCIA'), values = c('red', 'blue', 'black', 'yellow', 'green'))
```


2. Ploteo de las principales variables 

```{r}
library(GGally)
ggpairs(data = df.data[, c(2,3,4,5,6,13)])

```


3. Analisis tendencia del consumo

```{r}
ggplot(df.data, aes(x=FECHA, y=KWH)) +  
  geom_line() + geom_smooth(method="lm", colour="red") +
  geom_smooth(method="loess") + 
  scale_y_continuous(limits = c(0, 20000)) + 
  labs(x = "Evolucion Temporal",y = "Potencia KWH") + 
  ggtitle ('Analisis tendencia del consumo') + 
  theme(plot.title = element_text(hjust = 0.5))


```

Si nos fijamos en la linea roja, se aprecia que hay una ligera tendencia de disminucion del consumo a lo largo de estos dos anios, motivada por la bajada de consumo de los ultimos 3-4 meses de nuestros datos.  
Para extraer alguna conclusion mas solida habria que analizar un periodo mas amplio, pues al ser la disminucion mas pronunciada al final, podria ser por un motivo coyuntural en una epoca del año con extraordinario buen tiempo.
Nuestra serie esta compuesta justo por dos anios completos, que es el requisito minimo para que se pueda afirmar.


4. Analisis de la variable Climatizacion:

```{r}
# Diagrama de barras de la variable Climatizacion

ggplot(data = df.data, aes(x = CLIMATIZACION)) + 
  geom_bar(aes(fill = CLIMATIZACION)) + 
  labs(x = "Modo Climatizacion",y = "Dias Totales") + 
  ggtitle ('Diagrama de barras de la variable Climatizacion') + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Grafico circular de la variable Climatizacion

ggplot(data = df.data, aes(factor(1), fill=factor(CLIMATIZACION))) +
  geom_bar(width=1)+ coord_polar(theta="y") + 
  ggtitle ('Dias totales segun factor de Climatizacion') + 
  theme(plot.title = element_text(hjust = 0.5))

```

Tambien podemos ver que mas del 50% de los dias el sistema de climatizacion funciona en regimen de calefaccion y poco mas de un tercio en Refrigeracion


5. Analisis de la variable Afluencia:

```{r}
# Analisis Afluencia, agrupada por dia de la semana
# suma
aggregate(formula = AFLUENCIA ~ WEEKDAY, data = df.data, FUN = sum)
# media
aggregate(formula = AFLUENCIA ~ WEEKDAY, data = df.data, FUN = mean)

# AFLUENCIA agrupada por mes
# media
aggregate(formula = AFLUENCIA ~ MONTH, data = df.data, FUN = mean)
```


```{r}
# Vamos a representar los valores de asistencia con boxplot y ordenados por dia de la semana

df.data$WEEKDAY <-  factor(df.data$WEEKDAY,c('lunes','martes','miércoles','jueves','viernes','sábado','domingo'))

ggplot(df.data, aes(WEEKDAY, AFLUENCIA, fill=WEEKDAY)) + geom_boxplot() +
  labs(x = "Dia de la semana",y = "Personas") + 
  ggtitle ('Afluencia segun dia de la semana') + 
  theme(plot.title = element_text(hjust = 0.5))
```

Sorprendentemente, los dias de mayor asistencia son miercoles y jueves. Esperaba que fuera el sabado en particular.

```{r}
# Analizamos la asistencia por meses del año

df.data$MONTH <-  factor(df.data$MONTH, c('1','2','3','4','5','6','7','8','9','10','11','12'))

ggplot(df.data, aes(MONTH, AFLUENCIA, fill=MONTH)) + geom_boxplot() +
  labs(x = "Mes",y = "Personas") + 
  ggtitle ('Afluencia por mes') + 
  theme(plot.title = element_text(hjust = 0.5))

```

Tambien en mi opinion de manera sorprendente, los meses de mayor afluencia son julio y agosto, cuando imaginas que la gente esta de vacaciones y sale mas con el buen tiempo. Y es que casi dobla, de unas 12.000 personas durante los meses de invierno a casi 20.000 en verano.


6. Analisis de la variable potencia

```{r}
# POTENCIA (kWh)
# agrupada por fin de semana/dia de la semana
aggregate(formula = KWH ~ FINDE, data = df.data, FUN = mean)
# agrupada por meses
aggregate(formula = KWH ~ MONTH, data = df.data, FUN = mean)
```

```{r}
# Valores de potencia con boxplot y ordenados por dia de la semana

ggplot(df.data, aes(WEEKDAY, KWH, fill=WEEKDAY)) + geom_boxplot() +
  labs(x = "Dia de la semana",y = "KWH") + 
  ggtitle ('Consumo Potencia segun dia de la semana') + 
  theme(plot.title = element_text(hjust = 0.5))
```

Hay un contraste entre el dia de la semana que mas consumo hay (viernes) con el de mayor asistencia (miercoles). Tambien vemos que hay un aumento progresivo de desde el lunes (min) a viernes (max).

```{r}
# Analizamos la potencia consumida por meses del año

ggplot(df.data, aes(MONTH, KWH, fill=MONTH)) + geom_boxplot() +
  labs(x = "Mes",y = "KWH") + 
  ggtitle ('Consumo Potencia segun el mes') + 
  theme(plot.title = element_text(hjust = 0.5))

```

Los meses de mayor consumo son julio y agosto, que coinciden con los meses de mayor afluencia. Hay una relación directa entre la temperatura de confort en su interior y la afluencia al centro comercial


7. Analisis correlaciones

```{r}
# Vamos a ver la matriz de correlaciones entre las variables KWH (2), CCDD20(4), CHDD18(5) y AFLUENCIA (6)

pairs(~KWH+CCDD20+CHDD18+AFLUENCIA,data=df.data, main="Scatterplot Matrix")

```

Aunque hay bastante dispersion en los datos, en primer lugar destaca una fuerte dependencia entre Consumo vs Afluencia.
Tambien llama la atencion la relacion entre Consumo y CCDD20 (Refrigeracion). Esto es coherente, cuanta mayor diferencia de temperatura con el exterior, mayor consumo. Ya vimos anteriormente que en los meses de verano hay mucho mas consumo.
En cambio, en modo Calefaccion (CHDD18), al ser una linea plana significa que para el mismo consumo hay dias de poca diferencia de temperatura y otros dias con mayor gradiente termico.


```{r}
# Calculamos las correlaciones entre las variables anteriores, para confirmar numericamente las relaciones

correlation <- cor(df.data[,c(2,4,5,6)])
correlation
```


#########################################
#  CASOS DE ANALISIS SERIES TEMPORALES  #
#########################################

Recopilemos. Tenemos un dataset de un centro comercial. Hemos hecho tratamiento de datos y hemos generado plots para extraer informacion relevante de las variables.

Pero el objetivo principal con este dataset es desarrollar un modelo predictivo que prediga nuestro Consumo Real (KWH) y mejorar en la medida de lo posible, los resultados de su variable de prediccion (LB).

Para conseguirlo vamos a definir nuestro plan:  
1. Aplicar diferentes metodos de analisis a nuestra serie.  
2. Analizar la calidad predictiva de cada modelo.  
3. Escoger el modelo que mejor prediga.  
4. Comparar el error entre su modelo predictivo y nuestra mejor propuesta.  
5. Comprobar cual de las dos opciones es mejor.

La dificultad de analizar esta serie viene dada porque esta compuesta por muestras diarias en un ciclo estacional de dos años. Al tener justo el ciclo de dos años, se observa claramente una estacionalidad anual. Por un lado, tampoco es una serie de amplio rango lo suficientemente larga (ej. diez años). Por otro, la estacionalidad para periodos mas cortos no resulta evidente.


## CASO 1: Impacto causal utilizando modelos bayesianos de series de tiempo

Tal y como hemos comentado, queremos comparar el error de dos modelos predictivos, el actual y el nuevo. Asi que empezaremos por calcular el error actual.

```{r}
# Analizamos la evolucion de la variable Error

ST_Error=ts(df.data$ERROR, start= c(2016,3,1), end=c(2018,2,27), frequency = 365)
plot(ST_Error, xlab= "Periodo", ylab="% Error")

```

Como primera aproximacion, podemos observar que el modelo de prediccion ha mejorado a partir de la segunda mitad de 2017, ya que el % Error es mucho menor, tiende a concentrarse en la horquilla de -10% a +10%.

Vamos a suponer que a partir de la medicion 426, coincidiendo con el 01/05/2017, se han introducido mejoras en el algoritmo de prediccion y vamos a comparar la mejora que ha supuesto aplicando Causal Impact.

```{r}
pre_period <- c(1, 425)
post_period <- c(426, 725)

```

```{r}
impact <- CausalImpact(df.data$ERROR, pre_period, post_period)
plot(impact)

```

```{r}
summary(impact)
summary(impact, "report")
```

El resultado del analisis nos dice que la intervencion en el modelo redujo la prevision de ERROR en un 87%.


Ahora vamos a calcular la prediccion utilizando un modelo personalizado con bsts.model

```{r} 
ss <- AddLocalLevel(list(), df.data$KWH)
bsts.model <- bsts(df.data$KWH, ss, niter = 1000)
```

LOCAL LINEAR TREND: asume que tanto la media como la pendiente de la serie sigue un camino aleatorio.  
SEASONAL: representa la contribucion de cada mes al ciclo anual. Hay que especificarle el numero de periodos. Una buena opcion puede ser los meses del anio.  

```{r}
# Preparamos nuevos datos para el Bayesian, eliminando unas columnas que considero que no son de interes para el modelo
data.bsts <- df.data[,-c(3,7,9,13)]
```


Opcion 1. Tantos periodos como semanas del año
```{r}
starting.point <- 100
end.point <- 465
test.length <- 50
N_seasons <- 52
family1 <- 'gaussian'

# Variable que queremos predecir. Le decimos que empiece en starting.point y que termine en end.point.
Y <- window(data.bsts$KWH, start = starting.point, end = end.point)
# Local Linear Trend
ss <- AddLocalLinearTrend(list(), data.bsts$KWH)
# Seasonal
ss <- AddSeasonal(ss, data.bsts$KWH, nseasons = N_seasons)
# Fitear el modelo
bsts.model.1 <- bsts(KWH ~ . , state.specification = ss, family = family1, data = data.bsts, niter = 300, ping = 40, seed = 2017 )
# Get a suggested  number of burn-ins
burn <- SuggestBurn(0.1, bsts.model.1)
# Predecir
pred.bsts.1 <- predict.bsts(bsts.model.1, data.bsts[(end.point+1):(end.point+test.length),], burn = burn, quantiles = c(.025, .0975))
# Predicciones numericas
numeric.pred.bsts.1 <- pred.bsts.1$mean
 
mape.bsts.1 <- MAPE(data.bsts$KWH[(end.point +1):(end.point+test.length)], numeric.pred.bsts.1)

paste('MAPE: ', round(mape.bsts.1*100, 2), '%')
```

Ploteamos las predicciones:
```{r}

predictions.bsts.1 = data.frame(matrix(nrow = 100, ncol = 3))
colnames(predictions.bsts.1) = c('index', 'Real', 'Estimated.BSTS1')
predictions.bsts.1$index = seq(1,100,1)
predictions.bsts.1$Real = df.data$KWH[(end.point+1):(end.point+test.length)]
predictions.bsts.1$Estimated.BSTS1 = numeric.pred.bsts.1

ggplot() +
  geom_line(data = predictions.bsts.1, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.bsts.1, aes(x = index, y = Estimated.BSTS1 , color = 'Estimated.BSTS1')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.BSTS1'), values = c('red', 'blue')) +
  labs(y = "Potencia KWH") +
  ggtitle ('Opcion 1: Estacionalidad por semanas') + 
  theme(plot.title = element_text(hjust = 0.5))

```

El resultado de la prevision queda el valor estimado muy por debajo del real.
  
  
Opcion 2. Tantos periodos como meses del anio y le incluimos MonthlyAnnualCycle

```{r}
starting.point <- 100
end.point <- 465
test.length <- 50
N_seasons <- 12
family1 <- 'gaussian'

# Variable que queremos predecir. Le decimos que empiece en starting point y que termine en end.point.
Y <- window(data.bsts$KWH, start = starting.point, end = end.point)
# Local Linear Trend
ss <- AddLocalLinearTrend(list(), data.bsts$KWH[starting.point:end.point])
# Seasonal
ss <- AddSeasonal(ss, data.bsts$KWH[starting.point:end.point], nseasons = N_seasons)
# MonthlyAnnualCycle
ss <- AddMonthlyAnnualCycle(state.specification = ss, y = Y, date.of.first.observation = df.data$FECHA[1])
# Fitear el modelo
bsts.model.2 <- bsts(KWH ~ . , state.specification = ss, family = family1, data = data.bsts, niter = 500, ping = 50, seed = 2017 )
# Get a suggested  number of burn-ins
burn <- SuggestBurn(0.1, bsts.model)
# Predecir
pred.bsts.2 <- predict.bsts(bsts.model.2, data.bsts[(end.point+1):(end.point+test.length),], burn = burn, quantiles = c(.025, .0975))
# Predicciones numericas
numeric.pred.bsts.2 <- pred.bsts.2$mean

mape.bsts.2 <- MAPE(data.bsts$KWH[(end.point +1):(end.point+test.length)], numeric.pred.bsts.2)

paste('MAPE: ', round(mape.bsts.2*100, 2), '%')
 
```

Ploteamos las predicciones:

```{r}

predictions.bsts.2 = data.frame(matrix(nrow = 100, ncol = 3))
colnames(predictions.bsts.2) = c('index', 'Real', 'Estimated.BSTS1')
predictions.bsts.2$index = seq(1,100,1)
predictions.bsts.2$Real = data.bsts$KWH[(end.point+1):(end.point+test.length)]
predictions.bsts.2$Estimated.BSTS1 = numeric.pred.bsts.2

ggplot() +
  geom_line(data = predictions.bsts.2, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.bsts.2, aes(x = index, y = Estimated.BSTS1, color = 'Estimated.BSTS1')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.BSTS1'), values = c('red', 'blue')) +
  labs(y = "Potencia KWH") +
  ggtitle ('Opcion 2: Estacionalidad por meses') + 
  theme(plot.title = element_text(hjust = 0.5))

```


Al añadir una nueva componente de tendencia se mejora la prevision y baja sensiblemente el MAPE%. No obstante, las predicciones siguen lejos de la potencia consumida.

Podemos concluir que las predicciones no son de buena calidad.



## CASO 2: Metodo Holt-Winters

Vamos a hacer predicciones segun el Metodo Holt-Winters, que se caracteriza por hacer pronosticos utilizando un suavizado exponencial con un componente de tendencia y un componente estacional, es decir, suavizado exponencial triple.

```{r}
# Representamos los datos de consumo KWH
PotKWH <- ts(df.data$KWH, start= c(2016,03,01), end= c(2018,02,27), frequency = 365)
plot(PotKWH)

```

```{r}
# Se pasa la serie temporal a HoltWinter y se trazan los datos ajustados.
#hw <- HoltWinters(PotKWH, beta = FALSE , gamma = 0.5)
hw <- HoltWinters(PotKWH, alpha = 0.33, beta = FALSE, gamma = 0.5)
hw   # Para ver los parametros
plot(hw)
```

Justificacion de los parametros escogidos:  
Analizamos la web del paquete de Holt-Winters: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/HoltWinters.html  
  
gamma: Si se establece en FALSE, se ajusta un modelo no estacional. Y en mi opinion es una serie estacional, por lo que tiene que ser !=0  
beta: Si se establece en FALSE, la función hara suavizado exponencial. Es lo que queremos.  
Para fijar los valores de alpha y gamma tomamos esta web de referencia, que explica que son valores que oscilan entre 0 y 1 y que cuando estos valores no se conocen, recomienda los valores a usar.  
https://support.numxl.com/hc/es/articles/215653303-TESMTH-Suavizado-triple-exponencial-de-Holt-Winters  


```{r}
# Las predicciones son almacenadas bajo la variable fitted
head(hw$fitted)

# Suma de errores cuadráticos
head(hw$SSE)
```


Calculamos la previsión para los proximos 6 meses con un intervalo de confianza de 0,95 y representamos el pronostico junto con los valores reales y ajustados.

```{r}
forecast.hw <- predict(hw, n.ahead = 180, prediction.interval = T, level = 0.95)
plot(hw, forecast.hw)
```

He estimado las previsiones a 6 meses vista porque la serie es estacionaria y cada 6 meses hay un pico o un valle. Podemos ver que el modelo funciona y a partir de la fecha establecida, las predicciones van tomando la forma esperada.

Para tener una mejor representacion de las predicciones usando el metodo Holt-Winters, utilizo ggplot2. 

```{r}
# Usamos esta funcion que extrae algunos datos de los objetos HoltWinter y predict.HoltWinter y los alimenta a ggplot2
library(reshape)
 
 
HWggplot2<-function(ts_object,  n.ahead=12,  CI=.95,  error.ribbon='red', line.size=1){
     
    hw_object<-HoltWinters(ts_object, alpha = 0.33, beta = FALSE, gamma = 0.5)
     
    forecast<-predict(hw_object,  n.ahead=n.ahead,  prediction.interval=T,  level=CI)
     
     
    for_values<-data.frame(time=round(time(forecast),  3),  value_forecast=as.data.frame(forecast)$fit,  dev=as.data.frame(forecast)$upr-as.data.frame(forecast)$fit)
     
    fitted_values<-data.frame(time=round(time(hw_object$fitted),  3),  value_fitted=as.data.frame(hw_object$fitted)$xhat)
     
    actual_values<-data.frame(time=round(time(hw_object$x),  3),  Actual=c(hw_object$x))
     
     
    graphset<-merge(actual_values,  fitted_values,  by='time',  all=TRUE)
    graphset<-merge(graphset,  for_values,  all=TRUE,  by='time')
    graphset[is.na(graphset$dev),  ]$dev<-0
     
    graphset$Fitted<-c(rep(NA,  NROW(graphset)-(NROW(for_values) + NROW(fitted_values))),  fitted_values$value_fitted,  for_values$value_forecast)
     
     
    graphset.melt<-melt(graphset[, c('time', 'Actual', 'Fitted')], id='time')
     
  p<-ggplot(graphset.melt,  aes(x=time,  y=value)) + geom_ribbon(data=graphset, aes(x=time, y=Fitted, ymin=Fitted-dev,  ymax=Fitted + dev),  alpha=.2,  fill=error.ribbon) + geom_line(aes(colour=variable), size=line.size) + geom_vline(xintercept=max(actual_values$time),  lty=2) + xlab('Time') + ylab('Value') + labs(legend.position='bottom') + scale_colour_hue('')
    return(p)
 
}
```


Recuperamos la serie inicial, pero le aplicamos la funcion HWggplot2
```{r}
graph <- HWggplot2(PotKWH, n.ahead = 180)
graph

```

```{r}
# Ponemos leyendas al grafico
graph <- graph + labs(title = "Predicciones Metodo Holt-Winters en ggplot2")
graph <- graph + ylab("Potencia KWH")
graph <- graph + xlab("Tiempo")

graph

```

El modelo predictivo parece bastante bueno, aunque ofrece dudas por el amplio intervalo de confianza.


## CASO 3: METODO ARIMA

Los modelos ARIMA son una clase de modelo de pronostico que utiliza informacion historica para hacer predicciones y esta pensado para suavizar las fluctuaciones de la curva utilizamos el promedio movil.  
Cuanto mas ancha es la ventana de la media movil, mas suave se vuelve la serie original. En nuestro caso, podemos tomar la media movil semanal o mensual, suavizando la serie en algo mas estable y, por lo tanto, mas predecible.

Paso 1: Examinar datos

```{r}
ggplot(df.data, aes(FECHA, KWH)) + geom_line() + scale_x_date('MES')  + ylab("Consumo KWH") + xlab("")
```

```{r}
# Consideramos que no hay una relacion directa entre el consumo de un dia y del siguiente, la temperatura puede oscilar, la afluencia puede cambiar mucho, etc. Por si el dataset tuviera algunos valores volatiles, voy a eliminar valores atipicos de series temporales

KWH_ts = ts(df.data[, c('KWH')])

df.data$clean_KWH= tsclean(KWH_ts)

ggplot() + geom_line(data = df.data, aes(x = FECHA, y = clean_KWH)) + ylab('Consumo KWH Limpio')

```

Los datos son bastante similares.
Para suavizar las fluctuaciones de la curva utilizamos el promedio movil.
Cuanto mas ancha es la ventana de la media movil, mas suave se vuelve la serie original. En nuestro caso, podemos tomar la media movil semanal o mensual, suavizando la serie en algo mas estable y, por lo tanto, mas predecible.

```{r}
# Promedio movil o en ingles Mobile Average (ma)

df.data$KWH_ma = ma(df.data$clean_KWH, order=7) 
df.data$KWH_ma30 = ma(df.data$clean_KWH, order=30)


ggplot() + geom_line(data = df.data, aes(x = FECHA, y = clean_KWH, colour = "Consumo KWH Limpio")) +
  geom_line(data = df.data, aes(x = FECHA, y = KWH_ma, colour = "Promedio Movil Semanal"))  +
  geom_line(data = df.data, aes(x = FECHA, y = KWH_ma30, colour = "Promedio Movil Mensual"))  +
  ylab('Consumo')

```


Paso 2: Descomposicion de la serie

Los componentes basicos de un analisis de series de tiempo son la estacionalidad, la tendencia y el ciclo. El proceso de extraccion de estos componentes se conoce como descomposicion

```{r}
# Calculamos el doble componente estacional de los datos (semanal, anual) usando stl()

Consumo_ma = ts(na.omit(df.data$KWH_ma), frequency=7)
decomp = stl(Consumo_ma, s.window="periodic")
deseasonal_KWH <- seasadj(decomp)
plot(decomp)

```


Paso 3: Estacionariedad

La aplicacion de un modelo ARIMA requiere que la serie sea estacionaria. La prueba aumentada Dickey-Fuller (ADF) es una prueba estadistica formal para comprobar la estacionalidad, donde:  
Ho: La serie es no estacionaria: Tiene raiz unitaria  
H1: La serie es estacionaria: No Tiene raiz unitaria  


```{r}
adf.test(Consumo_ma, alternative = "stationary")
```

La serie original no es estacionaria porque tiene raiz unitaria (-2.05) y el valor p es 0.55

```{r}
adf.test(diff(Consumo_ma), alternative = "stationary")
```

En cambio, la serie en primera diferencia es estacionaria. El valor del estadistico es -9.5, con un valor p menor a 0.05 (0.01) por lo que la hipotesis nula ya se puede rechazar.
  

Paso 4: Diagramas de autocorrelacion

Los diagramas de autocorrelacion son una herramienta visual util para determinar si una serie es estacionaria. Estas parcelas tambien pueden ayudar a elegir los parametros de orden para el modelo ARIMA.

```{r}
# Identificacion de coeficientes para modelo ARIMA (p,d,q)
# ACF: auto correlation function, nos ayuda con el modelo q
Acf(Consumo_ma, main='')

# PACF: Partial autocorrelation function, nos ayuda con el modelo p
Pacf(Consumo_ma, main='')
```

Como hemos visto antes, la serie en primera diferencia es estacionaria. Lo que significa que nuestro modelo tendrá d=1

```{r}
Consumo_d1 = diff(deseasonal_KWH, differences = 1)
plot(Consumo_d1)
adf.test(Consumo_d1, alternative = "stationary")

```

Si observamos esta serie, esta serie diferenciada tiende a estacionaria. Los picos en momentos particulares pueden ayudar a informar la eleccion de p o q  para nuestro modelo

```{r}
Acf(Consumo_d1, main='ACF para Series Diferenciadas')
Pacf(Consumo_d1, main='PACF para Series Diferenciadas')
```

Analizando el grafico anterior ACF, se observa en retardos importantes en los picos 1, 2 y 7, lo que significa que son nuestros candidatos para q.
En cambio, la componente parcial PACF vemos que tiene claramente el pico en el 1, lo que supone el coeficiente p=1

Paso 5: Ajustar el modelo ARIMA

La funcion arima nos permite especificar explicitamente los parametros del modelo o generar automaticamente un conjunto optimo de (p, d, q) usando auto.arima. Esta funcion busca a traves de combinaciones de parametros y selecciona el conjunto que optimiza los criterios de ajuste del modelo.

```{r}
auto.arima(deseasonal_KWH, seasonal=FALSE)
```

Vemos que nos genera un modelo ARIMA(3,1,3) 


Paso 6: Evaluar e iterar

Vamos a examinar los graficos ACF y PACF para los residuos del modelo

```{r}
fit1<-auto.arima(deseasonal_KWH, seasonal=FALSE)
tsdisplay(residuals(fit1), lag.max=45, main='(3,1,3) Residuos del Modelo')
```

Hay un claro patron presente en ambos plots ACF, FAP que se repite en el retardo 7. Esto indica que nuestro modelo puede mejorarse con un nuevo parametro q = 7.

```{r}
fit2 = arima(deseasonal_KWH, order=c(3,1,7))

fit2

tsdisplay(residuals(fit2), lag.max=15, main='Residuales Modelo Estacional')

```


Paso 7: Pronosticos

Podemos especificar el horizonte de pronostico h (periodos por delante) para que se realicen las predicciones usando el modelo ajustado.

```{r}
fcast <- forecast(fit2, h=30)  
plot(fcast)
```

Otra opcion es superponer los datos reales con las previsiones en el ultimo bloque de unidades temporales

```{r}
# Calculo prediccion para los ultimos 2 meses, a partir 01/02/18
soporte <- window(ts(deseasonal_KWH), start=701)

fit_sin_soporte = arima(ts(deseasonal_KWH[-c(701:725)]), order=c(3,1,7))

prediccion_sin_soporte <- forecast(fit_sin_soporte,h=25)
plot(prediccion_sin_soporte, main=" ")
lines(ts(deseasonal_KWH))
```

Las predicciones no son muy buenas. Como mejorar el modelo?
Por ejemplo vamos a utilizar la funcion auto.arima con estacionalidad

```{r}
fit_con_estacionalidad = auto.arima(deseasonal_KWH, seasonal=TRUE)
fit_con_estacionalidad

```


```{r}
prediccion_con_estacionalidad <- forecast(fit_con_estacionalidad, h=30)
plot(prediccion_con_estacionalidad)
```

Los resultados predictivos son decepcionantes. He realizado diferentes pruebas de simulacion pero en ningun caso parece reaccionar la curva. 

En cualquier caso, para finalizar calculamos de nuevo los residuales con los parametros optimizados con auto.arima

```{r}
fit3 = arima(deseasonal_KWH, order=c(3,1,7))
fit3

tsdisplay(residuals(fit3), lag.max=15, main='Residuales Modelo Estacional')

```


Como los resultados no son convincentes, vamos a descomponer la serie con STR.

Paso 2(*): Descomp

```{r}
# Calculamos el componente estacional de los datos usando STR()
library(stR)

Consumo_ma_stR = ts(na.omit(df.data$KWH_ma), frequency=7)
decomp.fit = AutoSTR(Consumo_ma)

plot(decomp.fit)

```


## CASO 4: Arboles de clasificacion y regresion, RPART (CART) Tree

Vamos a intentarlo con un ultimo modelo predictivo, RPART. Para la prediccion de la serie temporal, no parece que cobren especial relevancia las variables Potencia Estimada (LB), Dia (DAY) y Anio (YEAR).

```{r}
# Eliminamos esas columnas de nuestro dataset y creamos el dataframe data.rpart
data.rpart <- df.data[,-c(3,7,9,13)]
```
 

1. TREE 1

Entrenamos el primer modelo.
```{r}
tree1 <- rpart(KWH ~ . , data = data.rpart )
```

```{r}
# Funcion para normalizar datos. El minimo a 0, el maximo a 1

normalize <- function(x){
  x <- (x - min(x))/(max(x)-min(x))
  return(x)
}
```

Vemos la importancia que cobra cada variable en la construcción de los árboles de prediccion y su peso en la estimacion de la potencia consumida

```{r}
tree1$variable.importance
normalize(tree1$variable.importance)
```

Representamos el arbol construido, es decir, tree1:

```{r}

rpart.plot(tree1, digits = 2,
           box.palette = viridis::viridis(10, option = "D", begin = 0.85, end = 0), 
           shadow.col = "grey65", col = "grey99")
```


Hacemos la prediccion de la serie. Tree1 ha sido entrenado con la serie temporal entera y vamos a predecir sobre la misma.

```{r}
# Primero creamos un data frame con los valores reales y las predicciones:

predictions.tree1 = data.frame(matrix(nrow = 725, ncol = 3))
colnames(predictions.tree1) = c('index', 'Real', 'Estimated.RPART')
predictions.tree1$index = seq(1,725,1)
predictions.tree1$Real = data.rpart$KWH
predictions.tree1$Estimated.RPART = predict(tree1) 
```


```{r}


ggplot() +
  geom_line(data = predictions.tree1, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.tree1, aes(x = index, y = Estimated.RPART, color = 'Estimated.RPART')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.RPART'), values = c('red', 'blue'))
              
```

Vemos que RPART predice aceptablemente bien la tendencia de la serie real, pero en los picos no es capaz de predecir bien. Como metrica para evaluar la prediccion de la serie utilizamos la metrica MAPE (mean absolute percentage error). 

```{r}
error.tree1 <- MAPE(predictions.tree1$Real, predictions.tree1$Estimated.RPART)
paste('MAPE: ', round(error.tree1*100, 2), '(%)')
```

El error es razonable dentro de lo que cabe, pero para mejorar predicciones hay que tunear un poco nuestro tree1 con rpart.control.


2. TREE 2

Vamos a especificar los siguientes parámetros:  
- minsplit  
- maxdepth  
- cp  


```{r}
tree2 <- rpart(KWH ~ . , data = data.rpart,
               control = rpart.control(minsplit = 2,
                                       max_depth = 20,
                                       cp = 0.00001))
```


Representamos el arbol, es bueno ver la comparacion a nivel de complejidad con el tree1, del que esperamos que tenga peores predicciones que tree2.

```{r}
plot(tree1)
plot(tree2, compress = TRUE)
```

Chequeamos el numero de splits y los comparamos con tree1

```{r}
paste('Numero de splits Tree2: ', tree2$cptable[dim(tree2$cptable)[1], 'nsplit'])
paste('Numero de splits Tree1: ', tree1$cptable[dim(tree1$cptable)[1], 'nsplit'])
```

Creamos nuevo data frame con las predicciones de tree2 y los valores reales

```{r}
predictions.tree2 = data.frame(matrix(nrow = 725, ncol = 3))
colnames(predictions.tree2) = c('index', 'Real', 'Estimated.RPART')
predictions.tree2$index = seq(1,725,1)
predictions.tree2$Real = data.rpart$KWH
predictions.tree2$Estimated.RPART = predict(tree2) 
```


Ploteamos la prediccion vs el valor real

```{r}
ggplot() +
  geom_line(data = predictions.tree2, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.tree2, aes(x = index, y = Estimated.RPART, color = 'Estimated.RPART')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.RPART'), values = c('red', 'blue'))
              
```

Vemos que practicamente ambas lineas se superponen.

Metrica MAPE
```{r}
error.tree2 <- MAPE(predictions.tree2$Real, predictions.tree2$Estimated.RPART)
paste('MAPE: ', round(error.tree2*100, 2), '(%)')
```

Se ha mejorado muchisimo la prediccion, pasando de un MAPE de 2.47% a un MAPE de 0.28 %.

Vamos a poner una combinacion de los hiperparametros de control para ver cual es la configuracion que mejor predice

```{r}
prueba.cp <- c(0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001)
mape.pruebas.cp <- c() 
for (i in prueba.cp){
  tree.aux <- rpart(KWH ~ . , data = data.rpart,
                    control = rpart.control(minsplit = 2,
                                       max_depth = 20,
                                       cp = i))
  mape.aux <- MAPE(df.data$KWH, predict(tree.aux))
  mape.pruebas.cp <- append(mape.pruebas.cp, mape.aux*100)
}

plot(-log10(prueba.cp), (mape.pruebas.cp), main = 'Metrica MAPE (%) en funcion del parametro cp', 
     xlab = 'cp (Transformado como -log10(cp))', ylab = 'Metrica MAPE (%)')
```

A medida que reducimos el cp, el MAPE baja, aunque esto puede ser un indicio de que el modelo esta bajo overfitting.

Tambien nos dice como estamos haciendo la segmentacion de los datos en un training y un test, no vale predecir sobre valores con los que hemos entrenado. Ademas los arboles de decision son muy propensos al overfiting. Si analizamos, en tree2 teniamos 63 split sobre 725 muestrras

Vamos a crear 2 set de training y 2 set de test:  
- data.train.1: 1/03/2016 -> 31/03/2017 (13 meses)  
- data.test.1: 1/04/2017 -> 30/04/2017 (1 mes)  
- data.train.2: 1/01/2017 -> 31/01/2018 (13 meses)  
- data.test.2: 1/02/2018 -> 27/02/2018 (1 mes)  
  

```{r}

data.train.1 <- data.rpart[1:395,]
data.test.1 <- data.rpart[396:425,]
data.train.2 <- data.rpart[306:700,]
data.test.2 <- data.rpart[701:725,]

```

Entrenamos el arbol tree.data.1 con data.train.1 y posteriormente predeciremos sobre data.test.1
```{r}
tree.data.1 <- rpart(KWH ~ . , data = data.train.1,
               control = rpart.control(minsplit = 2,
                                       max_depth = 20,
                                       cp = 0.00001))

predictions.data.1 <- data.frame(matrix(nrow = 30, ncol = 3))
colnames(predictions.data.1) = c('index', 'Real', 'Estimated.RPART')
predictions.data.1$index <- seq(1,30,1)
predictions.data.1$Real <- df.data[396:425, 2]
predictions.data.1$Estimated.RPART <- predict(tree.data.1, data.test.1)

```

Plot de la prediccion vs el consumo real
```{r}
ggplot() +
  geom_line(data = predictions.data.1, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.data.1, aes(x = index, y = Estimated.RPART, color = 'Estimated.RPART')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.RPART'), values = c('red', 'blue'))
```

Metrica MAPE
```{r}
tree.data.1.error <- MAPE(predictions.data.1$Real, predictions.data.1$Estimated.RPART)
paste('MAPE (%): ', round(tree.data.1.error*100,2))
```

Probamos a tunear los hiperparametros, por si podemos mejorar

```{r}
minsplit.data.1 <- c(2,3,4,5,6)
max_depth.data.1 <- c(5,7,9,11,13,15,17,21,23,25,27,30)
cp.data.1 <- c(0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001)

mape.1 <- 10000
hp.1.min_spl <- 0
hp.1.max_dep <- 0
hp.1.cp <- 0

for (i in minsplit.data.1){
  for (j in max_depth.data.1){
    for (k in cp.data.1){
      tree.aux <- rpart(KWH ~ . , data = data.train.1,
                    control = rpart.control(minsplit = i,
                                       max_depth = j,
                                       cp = k))
      mape.aux <- MAPE(data.test.1$KWH, predict(tree.aux, data.test.1))
  
      if (mape.aux < mape.1){
        hp.1.min_spl <- i
        hp.1.max_dep <- j
        hp.1.cp <- k
        mape.1 <- mape.aux
      } else{}
    }
  }
}
paste('La mejor combinación de hiperparámetros es: ') 
paste('min_split: ', hp.1.min_spl)
paste('max_depth: ', hp.1.max_dep)
paste('cp: ', hp.1.cp)
paste('Mape asociado a esta configuración de hiperparámetros: ', round(mape.1*100,2), '(%)')
```

Vamos a realizar el mismo procedimiento pero con el segundo set de training y test

```{r}
minsplit.data.2 <- c(2,3,4,5,6)
max_depth.data.2 <- c(5,7,9,11,13,15,17,21,23,25,27,30)
cp.data.2 <- c(0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001)

mape.2 <- 10000
hp.2.min_spl <- 0
hp.2.max_dep <- 0
hp.2.cp <- 0

for (i in minsplit.data.2){
  for (j in max_depth.data.2){
    for (k in cp.data.2){
      tree.aux <- rpart(KWH ~ . , data = data.train.2,
                    control = rpart.control(minsplit = i,
                                       max_depth = j,
                                       cp = k))
      mape.aux <- MAPE(data.test.2$KWH, predict(tree.aux, data.test.2))
  
      if (mape.aux < mape.2){
        hp.2.min_spl <- i
        hp.2.max_dep <- j
        hp.2.cp <- k
        mape.2 <- mape.aux
      } else{}
    }
  }
}
paste('La mejor combinación de hiperparámetros es: ') 
paste('min_split: ', hp.2.min_spl)
paste('max_depth: ', hp.2.max_dep)
paste('cp: ', hp.2.cp)
paste('Mape asociado a esta configuración de hiperparámetros: ', round(mape.2*100,2), '(%)')
```

Se obtiene la misma configuracion que en el caso anterior aunque disminuye ligeramente el MAPE.

Vamos a centrar la busqueda de los hiperparametros como se indica:

- Por lo visto en el caso de tree1 y tree2, cuando entrenabamos y predeciamos con la misma serie de datos, a mayor profundiad de los arboles se tiende al overfitting. En estos dos ultimos casos lo hemos comprobado viendo que la mejor predicción (menor MAPE), tomaba como max_depth el valor minimo posible (5). Es por esto que vamos a dirigir la busqueda de este hiperparametro hacia valores menores de maxima profundidad.

- En cuanto al minimo numero de splits, y tal como se ha experimentado podemos ver que es 6 para ambos casos y que a su vez es el mayor numero de la serie propuesta. Aumentaremos los valores de la serie.

- El valor de cp, de igual manera a la maxima profundidad, cuando entrenabamos y predeciamos con los mismos datos proporcionaba mejores resultados a medida que disminuiamos el parametro (induciendo al overfitting). En las nuevas predicciones, se ha encontrado como valor el 0.001 (minimo local) y es en sus valores adyacentes donde centraremos la busqueda.

```{r}
minsplit.data.3 <- c(6,7,8,9,10)
max_depth.data.3 <- c(1,2,3,4,5)
cp.data.3 <- c(seq(0.0001, 0.001, 0.0001),seq(0.001,0.01,0.001))

mape.3 <- 10000
hp.3.min_spl <- 0
hp.3.max_dep <- 0
hp.3.cp <- 0

for (i in minsplit.data.3){
  for (j in max_depth.data.3){
    for (k in cp.data.3){
      tree.aux <- rpart(KWH ~ . , data = data.train.1,
                    control = rpart.control(minsplit = i,
                                       max_depth = j,
                                       cp = k))
      mape.aux <- MAPE(data.test.1$KWH, predict(tree.aux, data.test.1))
  
      if (mape.aux < mape.3){
        hp.3.min_spl <- i
        hp.3.max_dep <- j
        hp.3.cp <- k
        mape.3 <- mape.aux
      }
    }
  }
}

paste('La mejor combinacion de hiperparametros es: ') 
paste('min_split: ', hp.3.min_spl)
paste('max_depth: ', hp.3.max_dep)
paste('cp: ', hp.3.cp)
paste('Mape asociado a esta configuracion de hiperparametros: ', round(mape.3*100,2), '(%)')

```

```{r}
minsplit.data.4 <- c(6,7,8,9,10)
max_depth.data.4 <- c(1,2,3,4,5)
cp.data.4 <- c(seq(0.0001, 0.001, 0.0001),seq(0.001,0.01,0.001))

mape.4 <- 10000
hp.4.min_spl <- 0
hp.4.max_dep <- 0
hp.4.cp <- 0

for (i in minsplit.data.4){
  for (j in max_depth.data.4){
    for (k in cp.data.4){
      tree.aux <- rpart(KWH ~ . , data = data.train.2,
                    control = rpart.control(minsplit = i,
                                       max_depth = j,
                                       cp = k))
      mape.aux <- MAPE(data.test.2$KWH, predict(tree.aux, data.test.2))
  
      if (mape.aux < mape.4){
        hp.4.min_spl <- i
        hp.4.max_dep <- j
        hp.4.cp <- k
        mape.4 <- mape.aux
      }
    }
  }
}

paste('La mejor combinacion de hiperparametros es: ') 
paste('min_split: ', hp.4.min_spl)
paste('max_depth: ', hp.4.max_dep)
paste('cp: ', hp.4.cp)
paste('Mape asociado a esta configuracion de hiperparametros: ', round(mape.4*100,2), '(%)')

```

En ambos casos, vemos que los 4 valores salen casi calcados. Asi que para terminar, vamos a entrenar un arbol para las dos series con los optimos de hiperparametros encontrados, predecimos y ploteamos:

```{r}
tree.tuned.1 <- rpart(KWH ~ . , data = data.train.1,
               control = rpart.control(minsplit = 6,
                                       max_depth = 1,
                                       cp = 0.0001))

predictions.1 <- data.frame(matrix(nrow = 30, ncol = 3))
colnames(predictions.data.1) = c('index', 'Real', 'Estimated.RPART')
predictions.1$index <- seq(1,30,1)
predictions.1$Real <- data.test.1$KWH
predictions.1$Estimated.RPART <- predict(tree.tuned.1, data.test.1)

tree.tuned.2 <- rpart(KWH ~ . , data = data.train.1,
               control = rpart.control(minsplit = 6,
                                       max_depth = 1,
                                       cp = 0.0001))
predictions.2 <- data.frame(matrix(nrow = 25, ncol = 3))
colnames(predictions.data.1) = c('index', 'Real', 'Estimated.RPART')
predictions.2$index <- seq(1,25,1)
predictions.2$Real <- data.test.2$KWH
predictions.2$Estimated.RPART <- predict(tree.tuned.2, data.test.2)

ggplot() +
  geom_line(data = predictions.1, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.1, aes(x = index, y = Estimated.RPART, color = 'Estimated.RPART')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.RPART'), values = c('red', 'blue'))

ggplot() +
  geom_line(data = predictions.2, aes(x = index, y = Real, color = 'Real')) + 
  geom_line(data = predictions.2, aes(x = index, y = Estimated.RPART, color = 'Estimated.RPART')) +
  scale_colour_manual('', breaks = c('Real', 'Estimated.RPART'), values = c('red', 'blue'))
```


################
# CONCLUSIONES #
################

De los 4 modelos analizados, podemos llegar a la conclusion que el modelo con el que hemos obtenido mejor resultado es el ultimo, el RPART. De las 4 opciones es el que tiene mejor calidad predictiva, por tanto, es el seleccionado para pasar a la siguiente fase.

Tal y como planteamos inicialmente, el objeto del estudio es comparar el error existente del modelo predictivo actual con el error segun un nuevo modelo desarrollado, para decidir cual de los dos modelos predice mejor.

En primer lugar, calculamos el error de las nuevas predicciones: real vs prediccion

```{r}
ERROR2 <- (df.data$KWH[701:725]-predictions.2$Estimated.RPART)/df.data$KWH[701:725] * 100

```

Creamos una nueva tabla compuesta por fecha y ambos errores
```{r}
Fecha <- df.data$FECHA[701:725]
ERROR1 <- df.data$ERROR[701:725]
ERRORvsERROR2 <- data.frame(Fecha,ERROR1, ERROR2)
View(ERRORvsERROR2)
```

Ploteamos ambos Errores en la misma grafica para compararlos mejor:
```{r}
ggplot() +  geom_line(data = ERRORvsERROR2 , aes(x = Fecha, y = ERROR1, color = 'ERROR1')) + 
  geom_line(data = ERRORvsERROR2, aes(x = Fecha, y = ERROR2 , color = 'ERROR2')) +
  scale_colour_manual('', breaks = c('ERROR1', 'ERROR2'), values = c('red', 'blue')) + 
  labs(x = "Evolucion Temporal",y = "% ERROR") + 
  ggtitle ('Error Modelo 1 vs Error Modelo 2') + 
  theme(plot.title = element_text(hjust = 0.5))
  
```

Segun podemos observar, el nuevo modelo predictivo predice mejor porque la grafica apenas se desvia del 0, mientras el modelo predictivo inicial tiene algunos picos del 15% o del 8% de error, vemos que claramente el Error1 es peor que el Error2.

