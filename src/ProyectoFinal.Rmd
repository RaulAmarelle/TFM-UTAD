---
title: "Trabajo Final Master"
author: "Raul Amarelle"
date: "21 de agosto de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###################
###  LIBRERIAS  ###
###################

```{r}
library(readxl)
library(cluster)
library(ggplot2)
library(mclust)
library(fpc)
library(dplyr)
library(stats)
library(lubridate)
library(CausalImpact)
library(data.table)
library(bsts)
library(zoo)
library(rpart) # decision tree method
library(rpart.plot) # tree plot
library(party) # decision tree method
library(forecast) # forecasting methods
library(tseries)
#library(ggforce) # visualization tools
#library(plotly) # interactive visualizations
library(grid) # visualizations
library(animation) # gif
```

```{r}
# Leemos los datos de nuestro data set

data <- read_excel("../dat/Datos.xls")
df.data <- as.data.frame(data)
View(df.data)
```

```{r}
# Funcion para normalizar datos. El minimo a 0, el maximo a 1

normalize <- function(x){
  x <- (x - min(x))/(max(x)-min(x))
  return(x)
}
```


############################
###  ANALISIS VARIABLES  ###
############################

Este dataset es una recopilacion de datos diarios de temperatura y potencia consumida relativos a un centro comercial.

Breve explicacion de las variables:
1. Fecha: fecha de la medicion, hay una medicion diaria
2. Estimado: no sirve de nada
3. Kwh: potencia consumida
4. LB: Linea base, es decir, la prediccion de potencia consumida
5 a 10. CCD o CCHD: Cooling-Degree Day o Cooling Heating Degree Day son temperaturas recogidas en 6 columnas. Es la diferencia entre el promedio diario de temperatura y una determinada temperatura base de referencia (suele ser la exterior). El centro comercial tiene dos modos de climatizacion: calentar o enfriar, por eso son siempre 3 ceros vs 3 numeros. 18, 19 y 20 es la temperatura base en ambos casos. Por eso el valor es siempre el mismo sumando o restando 1 de una columna a la siguiente.
11. Afluencia: Numero de personas visitantes.


Quiere decir que de las 3+3 columnas de temperatura, 2+2 son redundantes. Con quedarnos una columna de cada modo de climatizacion, es suficiente. Escogemos CCDD20 y CHDD18.


```{r}
# TRATAMIENTO DE DATOS Y PREANALISIS DEL DATASET

# Tenemos que tratar el dataset, podemos simplificarlo eliminando algunas columnas. La columna 2 se puede eliminar, no aporta nada. De las 3+3 columnas de temperatura, 2+2 son redundantes. Con quedarnos una columna de cada modo de climatizacion, es suficiente. Escogemos CCDD20 y CHDD18, que son las criticas

df.data <- df.data[,-c(2, 5, 6, 9, 10)]
View(df.data)
```

```{r}
# Vamos a hacer un preanalisis de variables

dim(df.data)
str(df.data)
summary(df.data)
```


##########################
###  NUEVAS VARIABLES  ###
##########################

```{r}
# Vamos a crear nuevas columnas para dia, mes y anio, nos pueden ser de utilidad para segmentar las predicciones segun periodo. Vamos a procesar las fechas porque estan como cadena de caracteres.

df.data$DAY <- 'NULO'
df.data$MONTH <- 'NULO'
df.data$YEAR <- 'NULO'

for (i in c(1:nrow(df.data))){
  my_date <- dmy(df.data$FECHA[i])
  df.data$DAY[i] <- day(my_date)
  df.data$MONTH[i] <- month(my_date)
  df.data$YEAR[i] <- year(my_date)
}

str(df.data)
View(df.data)
```


```{r}
# Las nuevas columnas creadas son caracteres. Transformamos valores a numericos. Tambien transformamos la columna fecha de caracteres a clase Date.

df.data$FECHA <- as.Date(df.data$FECHA, format="%d/%m/%Y")
df.data$YEAR <- as.numeric(as.character(df.data$YEAR))
df.data$MONTH <- as.numeric(as.character(df.data$MONTH))
df.data$DAY <- as.numeric(as.character(df.data$DAY))

str(df.data)
View(df.data)
```

```{r}
## Puede ser interesante crear una columna categorica Entre semana (ES) y Fin de semana (FS), porque los fines de semana hay previsiblemente mas asistencia

# Primero creamos la variable WeekDay como ('L', 'M', 'X', 'J', 'V', 'S', 'D') segun corresponda
df.data$WEEKDAY <- 'NULO'

seq1 <- c('M', 'X', 'J', 'V', 'S', 'D', 'L')
df.data$WEEKDAY[1:728] <- seq1
df.data$WEEKDAY[729] <- 'M'

# Creamos la variable categorica entre semana (ES) y fin de semana (FS)
df.data$FINDE <- ifelse(df.data$WEEKDAY %in% c('S', 'D'), 'FS', 'ES')

View(df.data)
```

```{r}
# Creamos la variable categorica Climatizacion, que tomara 3 valores:
#   - Heating
#   - Cooling
#   - Neutro

df.data$CLIMATIZACION <- ifelse(df.data$CCDD20 > 0, 'Cooling',
                                         ifelse(df.data$CHDD18 > 0, 'Heating', 'Neutro'))

View(df.data)
```


```{r}
# Creamos una nueva columna, que la llamaremos ERROR, que sera el % de error de la potencia consumida vs prevision de potencia
df.data$ERROR <- (df.data$KWH-df.data$LB)/df.data$KWH * 100

View(df.data)
```


########################
###  MISSING VALUES  ###
########################

```{r}
# Vamos a calcular los N/A del dataset
nas <- nrow(data[data$CHDD18!=0 & data$CCDD20!=0,])
nas

# Solo hay 4 muestras N/A, aprox el 0.5% de los datos
nas / nrow(df.data) *100

# Considero que puedo eliminar esas filas porque, aparte de ser un numero muy bajo y poco representativo, no se puede saber si ese dia el sistema funciono bajo regimen de calefaccion o refrigeracion, por lo que no podre extraer conclusiones
df.data <- df.data[!is.na(df.data$CCDD20),]

View(df.data)
```


################################
###  DISTRIBUCION VARIABLES  ###
################################

## VAMOS A CONGELAR ESTA PARTE, HASTA QUE TENGAMOS UN POCO MAS CLARO QUE BUSCAR
Parece razonable observar: 
La distribucion de las variables (las escalamos para observar mejor de forma conjunta la distribucion de todas)
Ya que estamos trabajando con una serie temporal, ver la evolucion que toman las variables

```{r}
# Distribucion con funciones de densidad
ggplot() +
  geom_density(data = df.data, aes(x = scale(KWH), colour = 'kWh')) +
  geom_density(data = df.data, aes(x = scale(LB), colour = 'LB')) +
  geom_density(data = df.data, aes(x = scale(CCDD20), colour = 'CCDD20')) +
  geom_density(data = df.data, aes(x = scale(CHDD18), colour = 'CHDD18')) + 
  geom_density(data = df.data, aes(x = scale(AFLUENCIA), colour = 'AFLUENCIA')) + 
  scale_colour_manual('', breaks = c('KWH', 'LB', 'CCDD20', 'CHDD18', 'AFLUENCIA'), values = c('red', 'blue', 'black', 'yellow', 'green'))
```

```{r}
# Serie temporal
SerieTemporal <- 1:nrow(df.data)

ggplot(data = df.data) +
  geom_line(aes(x = SerieTemporal, y = normalize(KWH), colour = 'KWH')) +
  geom_line(aes(x = SerieTemporal, y = normalize(LB), colour = 'LB')) + 
  geom_line(aes(x = SerieTemporal, y = normalize(CCDD20), colour = 'CCDD20')) + 
  geom_line(aes(x = SerieTemporal, y = normalize(CHDD18), colour = 'CHDD18')) +
  geom_line(aes(x = SerieTemporal, y = normalize(AFLUENCIA), colour = 'AFLUENCIA')) + 
  scale_colour_manual('', breaks = c('KWH', 'LB', 'CCDD20', 'CHDD18', 'AFLUENCIA'), values = c('red', 'blue', 'black', 'yellow', 'green'))

```

```{r}
# Muy complicado apreciar nada. Parece razonable pensar que dentro de un mismo anio la serie sigue mas o menos la misma distribucion. Vemos la distribucion de la serie para 2017
SerieTemporal2 <- seq(1,364)

ggplot(data = df.data[df.data$YEAR == '2017',]) +
  geom_line(aes(x = SerieTemporal2, y = normalize(KWH), color = 'KWH')) +
  geom_line(aes(x = SerieTemporal2, y = normalize(LB), color = 'LB')) + 
  geom_line(aes(x = SerieTemporal2, y = normalize(CCDD20), color = 'CCDD20')) + 
  geom_line(aes(x = SerieTemporal2, y = normalize(CHDD18), color = 'CHDD18')) +
  geom_line(aes(x = SerieTemporal2, y = normalize(AFLUENCIA), color = 'AFLUENCIA')) + 
  scale_colour_manual('', breaks = c('KWH', 'LB', 'CCDD20', 'CHDD18', 'AFLUENCIA'), values = c('red', 'blue', 'black', 'yellow', 'green'))
```


```{r}
# Vamos a comparar solo la serie temporal de KWH (real) y LB(prediccion)
ggplot(data = df.data) + 
  geom_line(aes(x = SerieTemporal, y = KWH, color = 'KWH')) +
  geom_line(aes(x = SerieTemporal, y = LB, color = 'LB')) + 
  scale_colour_manual('', breaks = c('KWH', 'LB'), values = c('red', 'blue'))
```

```{r}
# Vemos el diagrama de barras de la variable Climatizacion
ggplot(data = df.data, aes(x = CLIMATIZACION)) + geom_bar(aes(fill = CLIMATIZACION))
```


```{r}
# AFLUENCIA agrupada por dia de la semana
# suma
aggregate(formula = AFLUENCIA ~ WEEKDAY, data = df.data, FUN = sum)
# media
aggregate(formula = AFLUENCIA ~ WEEKDAY, data = df.data, FUN = mean)

# AFLUENCIA agrupada por mes
# media
aggregate(formula = AFLUENCIA ~ MONTH, data = df.data, FUN = mean)
```

```{r}
# POTENCIA (kWh)
# agrupada por fin de semana/dia de la semana
aggregate(formula = KWH ~ FINDE, data = df.data, FUN = mean)
# agrupada por meses
aggregate(formula = KWH ~ MONTH, data = df.data, FUN = mean)
```


```{r}
## CORRELACIONES ##
# Vamos a ver la matriz de correlaciones entre KWH (2), CCDD20(4), CHDD18(5) y AFLUENCIA (6)

correlation <- cor(df.data[,c(2,4,5,6)])
correlation
```


################################
###  ANALISIS CAUSAL IMPACT  ###
################################

Causal Impact using Bayesian Structural Time-Series Models

```{r}
# Reflejamos la evolucion del error, conviertiendo la variable en una serie temporal

origin <- as.Date("01/03/2016", format="%d/%m/%Y")
ST_Error=ts(df.data$ERROR, start = origin, frequency = 1)
plot(ST_Error, ylab="% Error")

# OJO, aunque ya es clase Date, la fecha la transforma en entero 
# Con as.Date sale lo mismo

```

Como primera aproximacion, podemos observar que el modelo de prediccion ha mejorado a partir de la muestra 450 aprox, ya que el % Error es mucho menor, tiende a concentrarse en la horquilla de -10% a +10%.

Vamos a suponer que a partir de la medicion 458, coincidiendo con el 01/06/2017, se han introducido mejoras en el algoritmo de prediccion.

```{r}
# Vamos a crear variable de datos, para no tener problemas luego con la clase
time.points <- seq(df.data$FECHA[1], df.data$FECHA[725], by = 1)
ST_data <- zoo(df.data$ERROR, time.points)
head(ST_data)
```


```{r}
# Para estimar un efecto causal, comenzamos por segmentar dos periodos, uno previo a la intervencion para capacitar el modelo y el segundo periodo, posterior a la intervencion para estimar el cambio.

pre.period <- c(df.data$FECHA[1], df.data$FECHA[456])
post.period <- c(df.data$FECHA[457], df.data$FECHA[725])
```

```{r}
impact <- CausalImpact(ST_data, pre.period, post.period)
plot(impact)
```

```{r}
summary(impact)
```

```{r}
summary(impact, "report")
```


#################################
###  TIME SERIES FORECASTING  ###
#################################

Using regression trees for forecasting

```{r}
# Realizamos la division de los datos en dos conjuntos, train y test, siguiendo muestreo aleatorio (80% train, 20% test)
set.seed(1)
ids <- sample(1:nrow(df.data), round(nrow(df.data)*.8))
data.train <- df.data[ids, ]  #80%
data.test <- df.data[-ids, ]  #20%
nrow(data.test)
```

```{r}
# Propuesta de tema para las graficas
theme_ts <- theme(panel.border = element_rect(fill = NA, 
                                              colour = "grey10"),
                  panel.background = element_blank(),
                  panel.grid.minor = element_line(colour = "grey85"),
                  panel.grid.major = element_line(colour = "grey85"),
                  panel.grid.major.x = element_line(colour = "grey85"),
                  axis.text = element_text(size = 13, face = "bold"),
                  axis.title = element_text(size = 15, face = "bold"),
                  plot.title = element_text(size = 16, face = "bold"),
                  strip.text = element_text(size = 16, face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 15),
                  legend.title = element_text(size = 16, face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
```

```{r}
# La linea LB es la prediccion de consumo
g <- ggplot(df.data, aes(x=FECHA, y=KWH)) +  geom_line() + 
  geom_line(aes(x=FECHA, y=LB), linetype = 5, color = "red") + geom_smooth(method="lm")
plot(g)

```

Se aprecia que hay una progresiva tendencia de disminucion del consumo a lo largo de estos dos anios, las medidas de ahorro energetico estan funcionando


```{r}
# Para ver un periodo mas en detalle, podemos segmentar los datos
# Ej: del 01/07/2016 al 30/09/2016

dia1=as.Date("2016/07/01",format="%Y/%m/%d")
dia2=as.Date("2016/09/30",format="%Y/%m/%d")
data.period <- seq(dia1, dia2, by=1)
data.period

```

```{r}
# NO FUNCIONA, PERO NO AFECTA

All.data.period <- df.data

for (i in c(1:nrow(All.data.period))){
  if (All.data.period$FECHA[i] %in% data.period){
    
  }else{
    All.data.period[i] <- All.data.period[-c(i),]
  }
    
}

View(All.data.period)

```

```{r}
# La idea es poner All.data.period como nuevos datos de un periodo determinado

g <- ggplot(All.data.period, aes(x=FECHA, y=KWH)) +  geom_line() + 
  geom_line(aes(x=FECHA, y=LB), linetype = 5, color = "red") + geom_smooth(method="lm")
plot(g)
```


# Construyendo caracteristicas para modelar

```{r}
# En primer lugar, calculamos la serie temporal del consumo semanal
period <- 1  # una medicion diaria
data_ts <- ts(df.data$KWH, freq = period * 7)  # medicion semanal
plot(data_ts, xlab="Semanal",ylab="KWH")
```

```{r}
decomp_ts <- stl(data_ts, s.window = "periodic", robust = TRUE)$time.series
plot(decomp_ts)
```

```{r}
trend_part <- ts(decomp_ts[,2])
trend_fit <- auto.arima(trend_part)
trend_for <- forecast(trend_fit, period)$mean
```

```{r}
trend_data <- data.table(KWH = c(decomp_ts[,2], trend_for),
                         Date = c(data.train$FECHA, data.test$FECHA),
                         Type = c(rep("Real", nrow(data.train)), rep("Forecast",
                                                                     nrow(data.test))))
 
ggplot(trend_data, aes(Date, KWH, color = Type)) +
  geom_line(size = 0.4) +
  labs(title = paste(trend_fit)) +
  theme_ts
```


#################################
###  ANALISIS SERIE TEMPORAL  ###
#################################

```{r}
analisis.ts = ts(df.data$KWH, frequency=1, start=df.data$FECHA[1])
plot(analisis.ts)
```

```{r}
# Le quito los ultimos 5 meses para calcular luego la prediccion
data.arima <- ts(df.data$KWH, frequency = 1, start = as.Date(c("01/03/2016"),format="%d/%m/%Y"), end = as.Date(c("30/09/2017"),format="%d/%m/%Y"))
forecast::auto.arima(data.arima)
```

```{r}
# Prediccion 5 meses, corresponde a h=149 medidas
fcast <- forecast::forecast(forecast::auto.arima(data.arima), h=149)
plot(fcast)
```

#########################################
##  SEGUNDO INTENTO METODOLOGIA ARIMA  ##
#########################################

#Paso 1: Examinar datos

```{r}
df.data$Date = as.Date(df.data$FECHA)

ggplot(df.data, aes(Date, KWH)) + geom_line() + scale_x_date('MES')  + ylab("Consumo KWH") + xlab("")
```

```{r}
# Consideramos que no hay una relacion directa entre el consumo de un dia y del siguiente, la temperatura puede oscilar, la afluencia puede cambiar mucho, etc. Por si el dataset tuviera algunos valores volatiles, voy a eliminar valores atipicos de series temporales

KWH_ts = ts(df.data[, c('KWH')])

df.data$clean_KWH= tsclean(KWH_ts)

ggplot() + geom_line(data = df.data, aes(x = Date, y = clean_KWH)) + ylab('Consumo KWH Limpio')

```

Los datos son bastante similares.
Para suavizar las fluctuaciones de la curva utilizamos el promedio movil.
Cuanto mas ancha es la ventana de la media movil, mas suave se vuelve la serie original. En nuestro caso, podemos tomar la media movil semanal o mensual, suavizando la serie en algo mas estable y, por lo tanto, mas predecible.

```{r}
# Promedio movil o en ingles Mobile Average (ma)

df.data$KWH_ma = ma(df.data$clean_KWH, order=7) 
df.data$KWH_ma30 = ma(df.data$clean_KWH, order=30)


ggplot() + geom_line(data = df.data, aes(x = Date, y = clean_KWH, colour = "Consumo KWH Limpio")) +
  geom_line(data = df.data, aes(x = Date, y = KWH_ma, colour = "Promedio Movil Semanal"))  +
  geom_line(data = df.data, aes(x = Date, y = KWH_ma30, colour = "Promedio Movil Mensual"))  +
  ylab('Consumo')

```


# Paso 2: Descomposicion de la serie

Los componentes basicos de un analisis de series de tiempo son la estacionalidad, la tendencia y el ciclo. El proceso de extraccion de estos componentes se conoce como descomposicion

```{r}
# Calculamos el componente estacional de los datos usando stl()

Consumo_ma = ts(na.omit(df.data$KWH_ma), frequency=30)
decomp = stl(Consumo_ma, s.window="periodic")
deseasonal_KWH <- seasadj(decomp)
plot(decomp)

```

# Paso 3: Estacionariedad

La instalacion de un modelo ARIMA requiere que la serie sea estacionaria. La prueba aumentada Dickey-Fuller (ADF) es una prueba estadistica formal para la estacionalidad, donde la hipotesis nula supone que la serie no es estacionaria

```{r}
adf.test(Consumo_ma, alternative = "stationary")
```

Con estos valores no queda claro si es estacionaria o no


# Paso 4: Diagramas de autocorrelacion

Los diagramas de autocorrelacion son una herramienta visual util para determinar si una serie es estacionaria. Estas parcelas tambien pueden ayudar a elegir los parametros de orden para el modelo ARIMA.

```{r}
# Identificacion de modelos ARIMA (p,d,q)
# ACF: auto correlation function, nos ayuda con el modelo q
Acf(Consumo_ma, main='')

# PACF: Partial autocorrelation function, nos ayuda con el modelo p
Pacf(Consumo_ma, main='')
```

En la segunda grafica vemos un patron oscilante alrededor de 0 sin una tendencia fuerte visible. Esto sugiere que la diferenciacion de los terminos del orden 1 (d=1) es suficiente y debe incluirse en el modelo.

```{r}
Consumo_d1 = diff(deseasonal_KWH, differences = 1)
plot(Consumo_d1)
adf.test(Consumo_d1, alternative = "stationary")

```

Si observamos esta serie, esta serie diferenciada tiende a estacionaria. Los picos en momentos particulares pueden ayudar a informar la eleccion de p o q  para nuestro modelo

```{r}
Acf(Consumo_d1, main='ACF para Series Diferenciadas')
Pacf(Consumo_d1, main='PACF para Series Diferenciadas')
```


# Paso 5: Ajustar el modelo ARIMA

La funcion arima nos permite especificar explicitamente los parametros del modelo o generar automaticamente un conjunto optimo de (p, d, q) usando auto.arima (). Esta funcion busca a traves de combinaciones de parametros y selecciona el conjunto que optimiza los criterios de ajuste del modelo.

```{r}
auto.arima(deseasonal_KWH, seasonal=FALSE)
```

Coeficiente ar1 p = 0.7436 nos dice que el siguiente valor de la serie se toma como un valor anterior atenuado por un factor de 0,7436 y depende del retardo de error anterior.


# Paso 6: Evaluar e iterar

Vamos a examinar los graficos ACF y PACF para los residuos del modelo

```{r}
fit1<-auto.arima(deseasonal_KWH, seasonal=FALSE)
tsdisplay(residuals(fit1), lag.max=45, main='(5,1,4) Residuos del Modelo')
```

Hay un claro patron presente en ACF, FAP y Residuos del Modelo que se repite en el retardo 7. Esto indica que nuestro modelo puede mejorarse con un nuevo parametro q = 7.

```{r}
fit2 = arima(deseasonal_KWH, order=c(5,1,7))

fit2

tsdisplay(residuals(fit2), lag.max=15, main='Residuales Modelo Estacional')

```


# Paso 7: Pronosticos

Podemos especificar el horizonte de pronostico h (periodos por delante) para que se realicen las predicciones usando el modelo ajustado.

```{r}
fcast <- forecast(fit2, h=60)
plot(fcast)
```

Otra opcion es superponer los datos reales con las previsiones en el ultimo bloque de unidades temporales

```{r}
# Calculo prediccion para los proximos 5 meses, a partir 01/10/17
soporte <- window(ts(deseasonal_KWH), start=578)

fit_sin_soporte = arima(ts(deseasonal_KWH[-c(578:725)]), order=c(5,1,7))

prediccion_sin_soporte <- forecast(fit_sin_soporte,h=150)
plot(prediccion_sin_soporte, main=" ")
lines(ts(deseasonal_KWH))
```

Las predicciones no son muy buenas. Como mejorar el modelo?
Por ejemplo vamos a utilizar la funcion auto.arima con estacionaliad

```{r}
fit_con_estacionalidad = auto.arima(deseasonal_KWH, seasonal=TRUE)
fit_con_estacionalidad

```

Los parametros optimizados con auto.arima son (3,1,3)

```{r}
prediccion_con_estacionalidad <- forecast(fit_con_estacionalidad, h=30)
plot(prediccion_con_estacionalidad)
```

Calculamos de nuevo los residuales con los parametros optimizados con auto.arima

```{r}
fit3 = arima(deseasonal_KWH, order=c(3,1,3))
fit3

tsdisplay(residuals(fit3), lag.max=15, main='Residuales Modelo Estacional')

```

